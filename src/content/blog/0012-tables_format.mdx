---
slug: storing-tables-efficiently-pandas
title: Storing tables efficiently with Pandas
meta_title: Storing tables efficiently
description: When working with pandas people usually need to store one or more tables. There are a lot of different formats to do that. In this post I am going to compare the performance between them.
date: 2019-04-03
image: "/images/blog/0012-tables_format.jpg"
categories: ["Python", "Benchmark"]
draft: false
---

<script type="module" src="/js/posts/0012-plots-tables-format.js"></script>

When working with **pandas** people usually need to store one or more tables. There are a lot of different formats to do that. In this post I am going to compare the performance between them.

## Table of Contents

[TOC]

## How test will be done
To do the tests I downloaded 3 datasets of different sizes:

* [Small](https://www.kaggle.com/contactprad/bike-share-daily-data) (56 KB)
* [Medium](https://www.kaggle.com/safegraph/visit-patterns-by-census-block-group) (233 MB)
* [Large](https://www.kaggle.com/city-of-seattle/seattle-checkouts-by-title) (6.62 GB)

I downloaded them from kaggle, one of the best places to find datasets.

The formats that I will test are:

* csv
* feather
* msgpack
* parquet
* pickle
* xlsx

## Test 1: Simple test
First of all I will check how they perform without changing any parameters. I will do 100 iterations with the small dataset and 10 with the medium one.

### Size small and iterations 100 with all extensions

First of all the average reading/writing times for each format.

<canvas id="chart_s0_i100_time" style="width:100%;height:300px;"></canvas>

<Notice type="info">
  It seems that `xlsx` is a slow option
</Notice>


### Size medium and iterations 10 with all extensions

<canvas id="chart_s1_i10_time" style="width:100%;height:300px;"></canvas>

With the medium dataframe the results are very similar.

<Notice type="warning">
 `xlsx` is a slow solution. I would only recommend it for small dataframes.
</Notice>

<canvas id="chart_s1_i10_size" style="width:100%;height:300px;"></canvas>

Regarding the file size both `xlsx` and `parquet` outperform the rest. If you look the pandas documentation you will see that **all extensions except `xlsx` and `feather` allow different types of compression.** Also `parquet` uses a more agresive compression by default. We need to test the formats and the different compressions.

## Test 2: Include compressions

This time each extensions will be tested using all posible compressions. The results are:

<table class="v-table v-table-right" align="center">
  <tr class="v-table-center">
    <th class="v-table-header">format</th>
    <th class="v-table-header">compression</th>
    <th class="v-table-header">read [s]</th>
    <th class="v-table-header">write [s]</th>
    <th class="v-table-header">size [MB]</th>
  </tr>
  <tr>
    <td rowspan="6" class="v-table-center"><b>csv</b></td>
    <td class="v-table-center">None</td>
    <td>3.05</td>
    <td>5.90</td>
    <td>236.10</td>
  </tr>
  <tr>
    <td class="v-table-center">bz2</td>
    <td>10.52</td>
    <td>24.44</td>
    <td>47.58</td>
  </tr>
  <tr>
    <td class="v-table-center">gzip</td>
    <td>4.26</td>
    <td>49.02</td>
    <td>65.80</td>
  </tr>
  <tr>
    <td class="v-table-center">infer</td>
    <td>3.09</td>
    <td>6.00</td>
    <td>236.10</td>
  </tr>
  <tr>
    <td class="v-table-center">xz</td>
    <td>9.92</td>
    <td>288.62</td>
    <td>43.99</td>
  </tr>
  <tr>
    <td class="v-table-center">zip</td>
    <td>4.05</td>
    <td>21.26</td>
    <td>66.44</td>
  </tr>
  <tr>
    <td class="v-table-center"><b>feather</b></td>
    <td class="v-table-center">feather</td>
    <td>0.61</td>
    <td>1.00</td>
    <td>213.38</td>
  </tr>
  <tr>
    <td rowspan="3"  class="v-table-center"><b>msgpack</b></td>
    <td class="v-table-center">None</td>
    <td>0.49</td>
    <td>1.32</td>
    <td>210.09</td>
  </tr>
  <tr>
    <td class="v-table-center">blosc</td>
    <td>0.48</td>
    <td>1.37</td>
    <td>202.88</td>
  </tr>
  <tr>
    <td class="v-table-center">zlib</td>
    <td>0.51</td>
    <td>2.05</td>
    <td>202.90</td>
  </tr>
  <tr>
    <td rowspan="4" class="v-table-center"><b>parquet</b></td>
    <td class="v-table-center">None</td>
    <td>0.77</td>
    <td>1.41</td>
    <td>209.58</td>
  </tr>
  <tr>
    <td class="v-table-center">brotli</td>
    <td>0.99</td>
    <td>27.04</td>
    <td>50.82</td>
  </tr>
  <tr>
    <td class="v-table-center">gzip</td>
    <td>1.00</td>
    <td>18.28</td>
    <td>56.75</td>
  </tr>
  <tr>
    <td class="v-table-center">snappy</td>
    <td>0.81</td>
    <td>1.87</td>
    <td>96.37</td>
  </tr>
  <tr>
    <td rowspan="6" class="v-table-center"><b>pickle</b></td>
    <td class="v-table-center">None</td>
    <td>0.47</td>
    <td>1.34</td>
    <td>207.54</td>
  </tr>
  <tr>
    <td class="v-table-center">bz2</td>
    <td>7.78</td>
    <td>18.51</td>
    <td>40.93</td>
  </tr>
  <tr>
    <td class="v-table-center">gzip</td>
    <td>1.49</td>
    <td>40.68</td>
    <td>54.85</td>
  </tr>
  <tr>
    <td class="v-table-center">infer</td>
    <td>0.48</td>
    <td>1.37</td>
    <td>207.54</td>
  </tr>
  <tr>
    <td class="v-table-center">xz</td>
    <td>6.26</td>
    <td>254.32</td>
    <td>38.05</td>
  </tr>
  <tr>
    <td class="v-table-center">zip</td>
    <td>2.07</td>
    <td>17.86</td>
    <td>55.43</td>
  </tr>
</table>

By plotting both reading and writing time is easier to se that writing times for `xz` compression are really slow.

<canvas id="chart_s1_i5_time" style="width:100%;height:300px;"></canvas>
<canvas id="chart_s1_i5_size" style="width:100%;height:300px;"></canvas>

It is not clear which formats and compressions work best. Let's plot reading/writing time vs file size.

<canvas id="chart_s1_i5_scatter_read" style="width:100%;height:300px;"></canvas>
<canvas id="chart_s1_i5_scatter_write" style="width:100%;height:300px;"></canvas>

<Notice type="warning">
  **csv** underperforms compared to the other formats
</Notice>

## Test 3: Using the big table

For this test I will only use the best formats from the previous test. Those are:

* feather
* msgpack
* parquet
* pickle

<table class="v-table v-table-right" align="center">
  <tr class="v-table-center">
    <th class="v-table-header">format</th>
    <th class="v-table-header">compression</th>
    <th class="v-table-header">read [min]</th>
    <th class="v-table-header">write [min]</th>
    <th class="v-table-header">size [GB]</th>
  </tr>
  <tr>
    <td class="v-table-center"><b>feather</b></td>
    <td class="v-table-center">feather</td>
    <td>-</td>
    <td>-</td>
    <td>4.24</td>
  </tr>
  <tr>
    <td rowspan="3"  class="v-table-center"><b>msgpack</b></td>
    <td class="v-table-center">None</td>
    <td>5.86</td>
    <td>6.32</td>
    <td>7.21</td>
  </tr>
  <tr>
    <td class="v-table-center">blosc</td>
    <td>5.45</td>
    <td>5.01</td>
    <td>6.50</td>
  </tr>
  <tr>
    <td class="v-table-center">zlib</td>
    <td>5.49</td>
    <td>5.55</td>
    <td>6.50</td>
  </tr>
  <tr>
    <td rowspan="4" class="v-table-center"><b>parquet</b></td>
    <td class="v-table-center">None</td>
    <td>1.15</td>
    <td>2.69</td>
    <td>5.96</td>
  </tr>
  <tr>
    <td class="v-table-center">brotli</td>
    <td>0.92</td>
    <td>11.22</td>
    <td>1.56</td>
  </tr>
  <tr>
    <td class="v-table-center">gzip</td>
    <td>0.97</td>
    <td>8.98</td>
    <td>2.00</td>
  </tr>
  <tr>
    <td class="v-table-center">snappy</td>
    <td>0.89</td>
    <td>2.78</td>
    <td>3.30</td>
  </tr>
  <tr>
    <td rowspan="6" class="v-table-center"><b>pickle</b></td>
    <td class="v-table-center">None</td>
    <td>1.38</td>
    <td>7.47</td>
    <td>6.25</td>
  </tr>
  <tr>
    <td class="v-table-center">bz2</td>
    <td>5.15</td>
    <td>17.47</td>
    <td>1.24</td>
  </tr>
  <tr>
    <td class="v-table-center">gzip</td>
    <td>1.88</td>
    <td>20.76</td>
    <td>1.81</td>
  </tr>
  <tr>
    <td class="v-table-center">infer</td>
    <td>1.46</td>
    <td>5.80</td>
    <td>6.25</td>
  </tr>
  <tr>
    <td class="v-table-center">xz</td>
    <td>3.46</td>
    <td>97.62</td>
    <td>0.97</td>
  </tr>
</table>

<Notice type="error">
  **feather** did not work since it has a restriction of 2 GB per column and it was exceeded.
</Notice>

<canvas id="chart_s2_i1_scatter_read" style="width:100%;height:300px;"></canvas>
<canvas id="chart_s2_i1_scatter_write" style="width:100%;height:300px;"></canvas>

With a file of this size it is clear that **parquet** is the best option. For compression it depends if your priority is file size or Input/Output time. For fast writing/reading use **parquet** without compression, for minimum file size `blosc` and `zlib` is a solution that is between the other two.

<Notice type="success">
  `parquet` is the best for big tables.
</Notice>

## Conlusions

1. `Excel` is only useful for **small** files when you are planning to open with an Excel program.
2. `csv` performs poorly
3. `pickle`, `msgpack` and `parquet` are good options
4. `feather` is another option when the table is not big
5. `parquet` is a good option in general and the best one for **big files**.
6. `parquet without compression` is the **fastest solution for big files** and `parquet with blosc` the **best at compressing big files**.
