---
slug: running-python-ecs-with-uv
title: Running Python Code in ECS with uv
meta_title: Building Fast and Reproducible ECS Python Deployments with uv
description: "Learn how to separate build and runtime stages using uv to create lightweight, versioned ECS environments. Package dependencies once, run anywhere."
date: 2025-10-24
image: /images/blog/9999-ship-python-containers.jpg
category: cloud_devops
tags: [AWS, ECS, Docker, uv, DE]
draft: false
---

## 0. Why Another ECS Setup?

Running Python workloads on ECS is simple in theory — but in practice, dependency builds slow everything down. Every task rebuilds the same environment, wasting time and compute.

The solution? **Package once, run anywhere.**

This post explains how to:

1. Build a **versioned virtual environment** once with `uv`.
2. Deploy a **minimal runtime container** that runs any version on ECS.
3. Automate setup with a simple shell script and S3.

<Notice type="info">
  By separating build and runtime, you get near-instant startup times, stable environments, and zero dependency drift between versions.
</Notice>

## 1. The Strategy

Run **small images** and **fetch the environment at runtime**. This plays to Fargate’s strengths (ephemeral tasks) and avoids paying the cold‑start penalty of large image pulls **every single run**.

### 1.0. What Fargate Optimizes For

* **No layer cache between tasks** → each task **pulls the full image** again.
* **Pull time scales with image size** → big images = slow starts.
* **Private subnets** without VPC endpoints can add NAT latency/cost.

<Notice type="info">
  Keep the image lean; move heavy Python deps out of the image. Treat S3 like a “layer store” for your virtualenv.
</Notice>

### 1.1. Two Approaches (and why one wins on Fargate)

| Approach                                     | What it means                                                | Pros                                                                                                        | Cons                                                                    |
| -------------------------------------------- | ------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------- |
| **A. Bake deps into the image**              | `pip install` during build; one fat image                    | Simple deploy; one immutable artifact                                                                       | Large image; slow pulls **every run**; rebuild image for any dep change |
| **B. Slim image + download venv at runtime** | Keep image minimal; fetch `venv_*.tar.gz` from S3 on startup | Tiny image → fast pulls; reuse one runtime image for many versions; faster iteration (swap venv, not image) | Slightly more bootstrap logic; needs S3 access & versioning             |

<Notice type="success">
  For short‑lived/batch tasks, **B** consistently starts faster: pull a ~80–100 MB image, then download a compressed venv from S3. Net startup is typically **tens of seconds**, not minutes.
</Notice>

### 1.2. The Pattern I Use (and this post documents)

**Package once, run anywhere**:

1. Build a **versioned** virtualenv tarball with `uv` (e.g., `venv_0.7.1.villoro.tar.gz`).
2. Push it to **S3** alongside `pyproject.toml`, `uv.lock`, and a versioned `entrypoint.py`.
3. Ship a **minimal runtime** image that, on start:

   * downloads the selected version (`-v <version>`) from S3,
   * extracts to `./.venv/`,
   * activates it, and
   * runs `entrypoint.py` with your args.

This keeps the Docker image stable (rarely changes) and lets you flip versions at run time.

### 1.3. Files & Layout (at a glance)

```
deploy/
├── docker/
│   ├── Dockerfile.venv        # build the venv tarball with uv
│   └── Dockerfile.runtime     # tiny runtime image
└── scripts/
    ├── upload_all.py          # CI: push venv/locks/entrypoint to S3
    ├── download_all.py        # runtime: fetch artifacts by version
    └── setup_and_run.sh       # runtime: bootstrap → activate → run
ecs_northius/
tests/
```

<Notice type="info">
  Venv tarballs and lockfiles are **versioned** (e.g., `uv`, `0.7.1.villoro`). Run any version in prod with `-v <version>` — great for hotfixes and A/B verification.
</Notice>

### 1.4. How this connects to entrypoints & params

This post focuses on **environment packaging + fast starts** on ECS. For dynamic entrypoints (import-by-string), robust CLI handling with `click`, and typed params via `pydantic`, see <FancyLink linkText="Effortless EMR: A Guide to Seamlessly Running PySpark Coder" url="https://villoro.com/blog/effortless-emr-guide-running-pyspark/" dark="true"/>. The same entrypoint approach drops into this ECS runtime pattern without change.

## 2. Building the venv (`Dockerfile.venv`)

We use `uv` because it’s fast, deterministic, and simple — a great fit for reproducible builds.

```Dockerfile
# 0. Pull images
ARG BUILD_FOR=linux/amd64
FROM --platform=${BUILD_FOR} ghcr.io/astral-sh/uv:latest AS uvbin
FROM --platform=${BUILD_FOR} python:3.13-slim-bookworm AS base

WORKDIR /app/
ENV PYTHONIOENCODING=utf-8 LANG=C.UTF-8 UV_LINK_MODE=copy UV_NO_PROGRESS=1 PIP_DISABLE_PIP_VERSION_CHECK=1

COPY --from=uvbin /uv /usr/local/bin/uv
COPY --from=uvbin /uvx /usr/local/bin/uvx
RUN uv --version && uvx --version

COPY pyproject.toml uv.lock ./
RUN uv venv --python 3.13 --copies && uv sync --frozen --no-dev

COPY ecs_northius ./ecs_northius
RUN uv pip install --python .venv/bin/python --no-deps .

ARG PACKAGE_VERSION
RUN mkdir -p /dist && tar -C .venv -czf /dist/venv_${PACKAGE_VERSION}.tar.gz .
FROM scratch AS export
COPY --from=base /dist/venv_*.tar.gz /dist/
```

Build and export:

```bash
docker build -f deploy/docker/Dockerfile.venv --output . . --build-arg PACKAGE_VERSION=0.1.0
```

<Notice type="info">
  The resulting `venv_0.1.0.tar.gz` is portable — upload it to S3 and reuse it across ECS tasks.
</Notice>

## 3. The Runtime (`Dockerfile.runtime`)

Here the focus is speed — no build tools, no compilers, no uv.

```Dockerfile
FROM python:3.13-slim-bookworm AS runtime

WORKDIR /app
ENV PYTHONUNBUFFERED=1 PYTHONDONTWRITEBYTECODE=1 PIP_DISABLE_PIP_VERSION_CHECK=1

RUN python -m pip install --no-cache-dir boto3 click loguru toml

COPY scripts .

ENTRYPOINT ["/bin/bash", "./setup_and_run.sh"]
```

**plot_speed**

<Notice type="info">
  The runtime image is small and starts fast because dependency resolution happened during the venv build.
</Notice>

## 4. Runtime Bootstrap Script (`setup_and_run.sh`)

What ECS runs by default:

```bash
echo 1. Downloading venv and config
python download_all.py "$@"

echo 2. Activating venv
. ./.venv/bin/activate

echo 3. Running ECS task. Using args="$@"
python entrypoint.py "$@"
```

Key points:

* `$@` lets you pass a version: `-v uv`.
* No dependency resolution here; it only downloads and activates.
* Use LF endings to avoid `/bin/sh` errors:

  ```
  *.sh text eol=lf
  *.py text eol=lf
  ```

For dynamic entrypoint and parameter management, check out <FancyLink linkText="Effortless EMR: A Guide to Seamlessly Running PySpark Coder" url="https://villoro.com/blog/effortless-emr-guide-running-pyspark/" dark="true"/> — the concepts complement this ECS setup perfectly.

## 5. Download Script (`download_all.py`)

Fetches all artifacts from S3: venv, entrypoint, and config.

```python
import tarfile, boto3, click, utils as u
from loguru import logger

def download_s3(origin, dest, bucket=u.BUCKET):
    logger.info(f"Downloading from {origin=} to {dest=}")
    boto3.client("s3").download_file(bucket, origin, dest)

def venv_extract_tar(filename, local_venv=".venv"):
    logger.info(f"Extracting {filename=} to {local_venv=}")
    with tarfile.open(filename, "r:gz") as tar:
        tar.extractall(local_venv, filter="fully_trusted")

@click.command()
@click.option("--version", "-v", required=True, help="Version to download")
def download_all(version):
    logger.info(f"Downloading all files (version='{version}')")
    download_s3(f"{u.S3_UV}/pyproject_{version}.toml", "pyproject.toml")
    download_s3(f"{u.S3_UV}/uv_{version}.lock", "uv.lock")
    download_s3(f"{u.S3_ENTRY}/entrypoint_{version}.py", "entrypoint.py")
    download_s3(f"{u.S3_VENV}/venv_{version}.tar.gz", "venv.tar.gz")
    venv_extract_tar("venv.tar.gz")
    logger.success("All downloads done")

if __name__ == "__main__":
    download_all()
```

<Notice type="warning">
  Python 3.14+ tightens tar extraction security. Use `filter="fully_trusted"` to avoid `AbsoluteLinkError` from absolute symlinks.
</Notice>

## 6. How It Runs in ECS

Pass the version when starting the task:

```bash
docker run --rm ecs/runtime -v uv
```

At runtime the container:

1. Downloads `venv_<version>.tar.gz`, `entrypoint.py`, and lock files.
2. Extracts and activates the venv.
3. Runs the entrypoint with your arguments.

<Notice type="info">
  You can run different versions in parallel (e.g., `-v uv` for dev, `-v 0.7.1.villoro` for prod) without rebuilding images.
</Notice>

## 7. CI/CD Flow

* `Dockerfile.venv` builds and uploads the venv tarball to S3.
* `Dockerfile.runtime` builds and pushes the runtime image to ECR.
* GitHub Actions keeps these steps separate for fast, reproducible deploys.

<Notice type="info">
  The runtime image is reused across multiple versions, only downloading the desired venv from S3. This dramatically reduces cold starts.
</Notice>

## 8. Troubleshooting

| Problem                            | Cause                           | Fix                                 |
| ---------------------------------- | ------------------------------- | ----------------------------------- |
| `AbsoluteLinkError`                | Symlinked Python binary in venv | Build with `uv venv --copies`       |
| `cannot open ./.venv/bin/activate` | CRLF line endings               | Enforce LF via `.gitattributes`     |
| Slow startup                       | Re-downloading venv each run    | Consider caching or a shared volume |

## 9. Key Takeaways

This pattern gives you:

* Fast ECS startups (no runtime builds).
* Versioned reproducibility via S3 artifacts.
* Lightweight runtime images.
* Clean separation between build and execution.

With **uv**, **Docker**, and **S3**, your ECS deployments become as fast and predictable as your local runs.

<Notice type="info">
  The same venv tarballs work for Lambda, Batch, or local debugging for strong parity across environments.
</Notice>
